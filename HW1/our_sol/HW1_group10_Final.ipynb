{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions:\n",
    "1. Collection is already opened. A function does not need to open a collection.\n",
    "\n",
    "2. Job_id index will start from 0.\n",
    "\n",
    "3. Data Model will be:\n",
    "   \n",
    "   MongoDB - \n",
    "   Job_id will be unique for job (and as a result uniqe for comapny by definition)\n",
    "   \n",
    "   Redis - \n",
    "   To improve the performance, 4 different calcualtions will be out sourced into redis. <br>\n",
    "   a. storing the next Job_id index.<br>\n",
    "   b. storing the job status.<br>\n",
    "   c. storing the mapping between job_id and the applied candidates' emails (redis set). <br>\n",
    "   d. storing the mapping between candidate's email and the companies it has been applied for (sorted set based on the date).<br>\n",
    "   \n",
    "4. company_name and location have 1-1 relationship (e.g: TAU is only located at 'Tel-Aviv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import time\n",
    "import datetime\n",
    "import redis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> add_company function: </b><br>\n",
    "receives a dictionary (a.k.a document) of 2 keys, decides whether the company name is unique, <br>\n",
    "Then adds 2 more attributes and inserts it to the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_company(company):\n",
    "    #print collection.find_one({\"company_name\":company['company_name']})\n",
    "    # validation: only insert if the company does not exist\n",
    "    if collection.find_one({\"company_name\":company['company_name']}) == None:\n",
    "        # insertion\n",
    "        # add jobs_list attribute\n",
    "        company['jobs_list'] = []\n",
    "        company['num_of_jobs'] = 0\n",
    "        collection.insert_one(company)\n",
    "        print company['company_name'],\"was successfully added\"\n",
    "    else:\n",
    "        print company['company_name'],\"is already exists in the system\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> add_job function: </b><br>\n",
    "Gets a dictionary (of the job), and a string of the company's name. validates that the company exists in the DB, <br>\n",
    "Then adds 2 attributes to the document. <br>\n",
    "We found it better to envovled Redis in the calculations and operations of the insert section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_job(job, company_name):\n",
    "    # validation: only insert if there is an associated company\n",
    "    company_doc = collection.find_one({\"company_name\":company_name})\n",
    "    if company_doc == None:\n",
    "        print \"Company does not exist in the system\"\n",
    "    else:\n",
    "    # insertion\n",
    "        # add candidates_list attribute\n",
    "        job['candidates_list'] = []\n",
    "        # assign auto increment job id\n",
    "        jobID = r.get('stud16:{}'.format('job_id'))\n",
    "        job[\"job_id\"] = jobID\n",
    "                \n",
    "        # add job_id to company mapping on reddis;\n",
    "        r.set('stud16:{}'.format(jobID), job['status'])\n",
    "                \n",
    "        # update the jobs list for the company\n",
    "        collection.update_many({\"company_name\":company_name},{\"$addToSet\":{\"jobs_list\":job}})\n",
    "        #collection.update_many({\"company_name\":company_name},{\"$inc\":{\"num_of_jobs\":1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> application function: </b><br>\n",
    "Takes the candidate's details, application time and *existing* job_id.\n",
    "Checks if the candidate hasn't applied yet and if the job status is currently open.\n",
    "If both conditions are met, the system adds the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def application(candidate, job_id, company_name): #application_time\n",
    "    # find the relevant job based on job_id\n",
    "    job_status = r.get('stud16:{}'.format(job_id))\n",
    "\n",
    "    # validation: check that this email was not applied for this job or if the job is closed.\n",
    "    # Return a boolean indicating if value is a member of set name\n",
    "    if (r.sismember('stud16:job{}_e'.format(job_id), candidate['email'])) | (job_status != 'open'):\n",
    "        print \"Candidate already applied for this position\"\n",
    "        \n",
    "    else:\n",
    "    #insert\n",
    "        #add the application time to the candidate\n",
    "        candidate[\"application_time\"] = pd.to_datetime(candidate['application_date'],dayfirst=True)\n",
    "        collection.update_one({\"company_name\":company_name, \"jobs_list.job_id\":job_id},{\"$push\":{\"jobs_list.$.candidates_list\":candidate}})\n",
    "        # Adding to redis the candidate's emaill to the job object\n",
    "        r.sadd('stud16:job{}_e'.format(job_id), candidate['email'])\n",
    "        \n",
    "        # Adding job application to the redis object\n",
    "        # Note <time.mktime(pd.to_datetime(application_time).timetuple())> will add the time as a score\n",
    "        r.zadd('stud16:{}'.format(candidate['email']),int(time.mktime(pd.to_datetime(candidate['application_date'],dayfirst=True).timetuple())),company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> update_job_status function: </b><br>\n",
    "Changes the status of a job according to the job id and company. <br>\n",
    "We found it necessary to update the changes also in Redis for a quick retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_job_status(company_name, job_id, new_status):\n",
    "    # Updating the status in MongoDB:\n",
    "    query = {'$and': [{\"company_name\": company_name}, {\"jobs_list.job_id\" : job_id}]}\n",
    "    collection.update_one(query, {\"$set\": {\"jobs_list.$.status\":new_status}, \n",
    "                          \"$currentDate\": {\"jobs_list.$.lastModified\": True}})\n",
    "    # Updating the status in Redis:\n",
    "    r.set('stud16:{}'.format(job_id), new_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> show_number_of_jobs function: </b><br>\n",
    "Showing the number of open jobs per requested location and job title.\n",
    "We only show the result to the user, So there's no need to save the result in redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_number_of_jobs(location, job_title):\n",
    "    aggregation_function = collection.aggregate([\n",
    "      { \"$unwind\": \"$jobs_list\" },\n",
    "      { \"$match\": { \"$and\": [{\"jobs_list.status\": \"open\", \"jobs_list.location\": \"Tel Aviv\",\n",
    "                              \"jobs_list.job_title\": 'product'}] } }     \n",
    "    ]\n",
    "    )\n",
    "    number_of_open_jobs_at_location = pd.DataFrame(list(aggregation_function)).shape[0]\n",
    "    print \"\\nNumber of open {} positions at {} is: {}\".format(job_title, location, number_of_open_jobs_at_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> show_candidates function: </b><br>\n",
    "Showing the candidates' emails for a specific job id, sorted by the number of matches between skills and requirements. <br> \n",
    "similary to the previous function, we only show the result to the user, \n",
    "hence there's no need to save it in redis. <br>\n",
    "<b> Assumption: we assumed that the wanted output should be sorted such that the emails with a lower matches between candidate's skills and required skills will appear at the top, and emails with higher matches will appear at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_candidates(company_name, job_id):\n",
    "    # Getting the list of skills as required for the job\n",
    "    skills = collection.aggregate([\n",
    "            { \"$unwind\": \"$jobs_list\" },\n",
    "            { \"$match\": {\"jobs_list.job_id\" : job_id}},\n",
    "            { \"$project\": {\"skills\" : \"$jobs_list.skills\"}}\n",
    "    ])\n",
    "    jobs_list_of_skills = pd.DataFrame(list(skills))['skills'].iloc[0]\n",
    "    \n",
    "    # Getting a df with the candidates' email and skills\n",
    "    emails = collection.aggregate([\n",
    "          { \"$unwind\": \"$jobs_list\" },\n",
    "          { \"$match\": { \"jobs_list.job_id\": job_id }},\n",
    "          { \"$unwind\": \"$jobs_list.candidates_list\" },\n",
    "          { \"$project\": {\"_id\": \"$jobs_list.job_id\", \"skills\": \"$jobs_list.candidates_list.skills\",\n",
    "                         \"emails\": '$jobs_list.candidates_list.email' } }\n",
    "    ])\n",
    "        \n",
    "    job_emails_skills_df = pd.DataFrame(list(emails)).rename(columns={\"_id\":\"Job_id\"})\n",
    "    \n",
    "    # Creating a similarity index such that lower score indicates of high similarity (high number of matches).\n",
    "    # e.g: value of 0 for this index means that there's a perfect match!\n",
    "    job_emails_skills_df['similarity_to_requirements'] = job_emails_skills_df['skills'].apply(lambda row:\n",
    "                                                         len(set(jobs_list_of_skills) - set(row)))\n",
    "    # Ordering in an ascending order of matches, such that the lowest number of matches is first and the highest\n",
    "    # number of matches is last\n",
    "    job_emails_skills_df.sort_values(by= 'similarity_to_requirements', ascending= False, inplace= True)\n",
    "    return job_emails_skills_df['emails']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> count_jobs_by_date Report 1: </b><br>\n",
    "Returns a DF with three columns (one of them is indexed): date, number of open jobs, number of closed jobs, ordered by date (in ascending order). <br>\n",
    "<b> Note that if a job's status was changed to 'closed', it will be counted as 'closed' from its publish date (because 'lastModifiedDate' is always 2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_jobs_by_date():\n",
    "    #Creating the DataFrame - with rows as index (date for each day for the whole year)\n",
    "    df = pd.DataFrame(columns=['# of opened jobs', '# of closed jobs'], index=pd.date_range(start='1/1/2020', end='31/12/2020'))\n",
    "    \n",
    "    # aggregation to get the number of opened jobs for each date:\n",
    "    aggregation_function = collection.aggregate([\n",
    "    { \"$unwind\": \"$jobs_list\"},\n",
    "    { \"$match\": {\"jobs_list.status\": \"open\"} },\n",
    "    { \"$group\": {\"_id\": \"$jobs_list.publish_date\", \"open_jobs\": {\"$sum\": 1}}}\n",
    "    ])\n",
    "    \n",
    "    # Filling the DF with the opened jobs in the correct dates:\n",
    "    for row in aggregation_function:\n",
    "        df.loc[row[\"_id\"],\"# of opened jobs\"] = row[\"open_jobs\"]\n",
    "    \n",
    "    # aggregation to get the number of colsed jobs for each date:\n",
    "    aggregation_function = collection.aggregate([\n",
    "    { \"$unwind\": \"$jobs_list\"},\n",
    "    { \"$match\": {\"jobs_list.status\": \"close\"} },\n",
    "    { \"$group\": {\"_id\": \"$jobs_list.publish_date\", \"closed_jobs\": {\"$sum\": 1}}}\n",
    "    ])\n",
    "    \n",
    "    # Filling the DF with the closed jobs in the correct dates:\n",
    "    for row in aggregation_function:\n",
    "        df.loc[row[\"_id\"],\"# of closed jobs\"] = row[\"closed_jobs\"]\n",
    "    \n",
    "    # Now w'd like to apply a commulative sum to reflect the correct jobs' status distribution:\n",
    "    df = df.fillna(0)   \n",
    "    df['# of opened jobs'] = df['# of opened jobs'].cumsum()\n",
    "    df['# of closed jobs'] = df['# of closed jobs'].cumsum()\n",
    "    \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> count_candidates_by_job Report 1: </b><br>\n",
    "Return the number of candidates, grouped by job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_candidates_by_job():\n",
    "    threshold = (datetime.datetime.today() - datetime.timedelta(days=30)) # setting thershold (30 days) for agg. func.\n",
    "    # aggregate function - returns no. of applications from subdocuments of each job\n",
    "    a = collection.aggregate([\n",
    "      { \"$unwind\": \"$jobs_list\" },\n",
    "      { \"$unwind\": \"$jobs_list.candidates_list\" },\n",
    "      { \"$project\": {\"_id\": '$jobs_list.job_id', \"time\": \"$jobs_list.candidates_list.application_time\"}},\n",
    "    ]\n",
    "    )\n",
    "    # Preparing the final df to return - # of candidates per job id:\n",
    "    candidates = pd.DataFrame(list(a))\n",
    "    count_jobs_for_id_df = candidates.loc[candidates['time'] > threshold].groupby(by= '_id').count().reset_index()\n",
    "    \n",
    "    if count_jobs_for_id_df.empty:\n",
    "        return \"No jobs with applications during the last 30 days\"\n",
    "    return count_jobs_for_id_df.rename(columns={'_id':\"Job ID\", \"time\": \"Number of Candidates\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Recovery function: </b><br>\n",
    "This function inserts the needed data back to Redis should it suddenly fail or shut-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recovery():\n",
    "    # job_id\n",
    "    recover_id = collection.aggregate([\n",
    "      { \"$unwind\": \"$jobs_list\" },\n",
    "      { \"$project\": {\"_id\": { \"$max\": \"$jobs_list.job_id\"}}},\n",
    "    ]\n",
    "    )\n",
    "    job_id = pd.DataFrame(list(recover_id)).max().values # get the latest job_id given in the db\n",
    "    if job_id.size == 0:\n",
    "        r.set('stud16:{}'.format('job_id'), 0) \n",
    "        return     # Exit the function\n",
    "    else:\n",
    "        r.set('stud16:{}'.format('job_id'), int(job_id[0]) + 1)\n",
    "        \n",
    "    # map job_id -> job status\n",
    "    map_job_id_job_status = collection.aggregate([\n",
    "      { \"$unwind\": \"$jobs_list\" },\n",
    "      { \"$project\": {\"_id\": \"$jobs_list.job_id\",\"status\":\"$jobs_list.status\"}}\n",
    "    ]\n",
    "    )\n",
    "    job_id_status_df = pd.DataFrame(list(map_job_id_job_status))\n",
    "    if not job_id_status_df.empty:\n",
    "        job_id_status_df['_id'] = job_id_status_df['_id'].apply(lambda r: \"stud16:{}\".format(r)) # creating the key\n",
    "        job_id_status_dict = job_id_status_df.set_index('_id').T.to_dict('records')[0]\n",
    "        r.mset(job_id_status_dict) # insert to Redis\n",
    "            \n",
    "    # job_id_e -> set(emails)\n",
    "    email_set = collection.aggregate([\n",
    "      { \"$unwind\": \"$jobs_list\" },\n",
    "      { \"$unwind\": \"$jobs_list.candidates_list\" },\n",
    "      { \"$project\": {\"_id\": \"$jobs_list.job_id\",\"email\":\"$jobs_list.candidates_list.email\"}}\n",
    "    ]\n",
    "    )\n",
    "    email_set = pd.DataFrame(list(email_set))\n",
    "    email_set = email_set.groupby('_id')['email'].apply(list).to_frame()\n",
    "    email_set['job_id'] = email_set.index\n",
    "    email_set['job_id'] = email_set['job_id'].apply(lambda r: 'stud16:job{}_e'.format(r) ) # applying key format for Redis\n",
    "    email_set = email_set.set_index('job_id').T.to_dict('records')[0] # converting to dict (key,email set)\n",
    "    \n",
    "    # insert to Redis each value at a time:\n",
    "    for k,v in email_set.items():\n",
    "        for e in v:\n",
    "            r.sadd(k,e)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> EXECUTION function: </b><br>\n",
    "This function applies all of the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute():\n",
    "    recovery()\n",
    "    add_company({'company_name':'TAU', 'company_description':'University'})\n",
    "    add_job({'job_title':'bi developer', 'location': 'Tel Aviv',\n",
    "             'skills':['python','big data','mongodb'],'status':'open',\n",
    "             'publish_date':'05-02-2020'},'TAU')\n",
    "    application({'candidate_name':'laura', 'email':'laura@gmail.com',\n",
    "                 'linkedin':'https://www.linkedin.com/in/laura/', \"skills\": ['java','sql'],\n",
    "                'application_date':'05-02-2020 15:00:00'}, '0', 'TAU')\n",
    "    \n",
    "    update_job_status('TAU', '0', 'close')\n",
    "    \n",
    "    show_number_of_jobs('Tel Aviv', 'bi developer')\n",
    "    \n",
    "    print\n",
    "    print \"Candidates' emails for the job (sorted):\"\n",
    "    print show_candidates('TAU', '0')\n",
    "    print\n",
    "    print \"Report 1 - Jobs status distribution per date:\"\n",
    "    print count_jobs_by_date()\n",
    "    print\n",
    "    print \"Report 2 - Candidates by Job:\"\n",
    "    print count_candidates_by_job()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list(collection.find())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print \"Candidates' emails for the job (sorted):\"\n",
    "# show_candidates('TAU', '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing Connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = redis.StrictRedis(host='bdl1.eng.tau.ac.il', port=6379)  # creating reddis connection\n",
    "client = MongoClient() # creating MongoDB connection\n",
    "db = client['stud16']\n",
    "# clean up the collection before start working\n",
    "db.hm1_stud16.drop()\n",
    "# creating new collection\n",
    "collection = db.hm1_stud16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.flushall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute - run me!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAU was successfully added\n",
      "\n",
      "Number of open bi developer positions at Tel Aviv is: 0\n",
      "\n",
      "Candidates' emails for the job (sorted):\n",
      "0    laura@gmail.com\n",
      "Name: emails, dtype: object\n",
      "\n",
      "Report 1 - Jobs status distribution per date:\n",
      "            # of opened jobs  # of closed jobs\n",
      "2020-01-01                 0                 0\n",
      "2020-01-02                 0                 0\n",
      "2020-01-03                 0                 0\n",
      "2020-01-04                 0                 0\n",
      "2020-01-05                 0                 0\n",
      "2020-01-06                 0                 0\n",
      "2020-01-07                 0                 0\n",
      "2020-01-08                 0                 0\n",
      "2020-01-09                 0                 0\n",
      "2020-01-10                 0                 0\n",
      "2020-01-11                 0                 0\n",
      "2020-01-12                 0                 0\n",
      "2020-01-13                 0                 0\n",
      "2020-01-14                 0                 0\n",
      "2020-01-15                 0                 0\n",
      "2020-01-16                 0                 0\n",
      "2020-01-17                 0                 0\n",
      "2020-01-18                 0                 0\n",
      "2020-01-19                 0                 0\n",
      "2020-01-20                 0                 0\n",
      "2020-01-21                 0                 0\n",
      "2020-01-22                 0                 0\n",
      "2020-01-23                 0                 0\n",
      "2020-01-24                 0                 0\n",
      "2020-01-25                 0                 0\n",
      "2020-01-26                 0                 0\n",
      "2020-01-27                 0                 0\n",
      "2020-01-28                 0                 0\n",
      "2020-01-29                 0                 0\n",
      "2020-01-30                 0                 0\n",
      "...                      ...               ...\n",
      "2020-12-02                 0                 1\n",
      "2020-12-03                 0                 1\n",
      "2020-12-04                 0                 1\n",
      "2020-12-05                 0                 1\n",
      "2020-12-06                 0                 1\n",
      "2020-12-07                 0                 1\n",
      "2020-12-08                 0                 1\n",
      "2020-12-09                 0                 1\n",
      "2020-12-10                 0                 1\n",
      "2020-12-11                 0                 1\n",
      "2020-12-12                 0                 1\n",
      "2020-12-13                 0                 1\n",
      "2020-12-14                 0                 1\n",
      "2020-12-15                 0                 1\n",
      "2020-12-16                 0                 1\n",
      "2020-12-17                 0                 1\n",
      "2020-12-18                 0                 1\n",
      "2020-12-19                 0                 1\n",
      "2020-12-20                 0                 1\n",
      "2020-12-21                 0                 1\n",
      "2020-12-22                 0                 1\n",
      "2020-12-23                 0                 1\n",
      "2020-12-24                 0                 1\n",
      "2020-12-25                 0                 1\n",
      "2020-12-26                 0                 1\n",
      "2020-12-27                 0                 1\n",
      "2020-12-28                 0                 1\n",
      "2020-12-29                 0                 1\n",
      "2020-12-30                 0                 1\n",
      "2020-12-31                 0                 1\n",
      "\n",
      "[366 rows x 2 columns]\n",
      "\n",
      "Report 2 - Candidates by Job:\n",
      "No jobs with applications during the last 30 days\n"
     ]
    }
   ],
   "source": [
    "execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks - for self use & debugging - do not notice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #The following are part of the checks and inputs we used to validate our data model:\n",
    "# company = {'company_name':'TAU', 'company_description':'University'}\n",
    "# add_company(company)\n",
    "\n",
    "# company = {'company_name':'BGU', 'company_description':'University'}\n",
    "# add_company(company)\n",
    "\n",
    "# job ={'job_title':'analyst', 'location': 'Tel Aviv',\n",
    "#       'skills':['python','big data','mongodb'],'status':'open','publish_date':'01-15-2020'}\n",
    "# add_job(job, 'TAU')\n",
    "\n",
    "# print collection.find_one({\"company_name\":'TAU'})\n",
    "\n",
    "# job ={'job_title':'product', 'location': 'Tel Aviv',\n",
    "#       'skills':['python','big data','mongodb'],'status':'open','publish_date':'01-02-2020'}\n",
    "# add_job(job, 'TAU')\n",
    "\n",
    "# job ={'job_title':'product', 'location': 'Tel Aviv',\n",
    "#       'skills':['python','big data','mongodb'],'status':'open','publish_date':'01-02-2020'}\n",
    "# add_job(job, 'TAU')\n",
    "\n",
    "\n",
    "# application({'candidate_name':'yuval', 'email':'yuval@gmail.com',\n",
    "# 'linkedin':'https://www.linkedin.com/in/laura/', 'skills':['python','sql'],\n",
    "# 'application_date':'01-05-2019 15:00:00'}, '1','BGU')\n",
    "\n",
    "# application({'candidate_name':'aaa', 'email':'tamir@gmail.com',\n",
    "#     'linkedin': 'https://www.linkedin.com/in/laura/', 'skills':['excel','msproject'],\n",
    "#     'application_date':'30-12-2020 15:00:00'}, '11', 'TAU')\n",
    "\n",
    "# print collection.find_one({\"company_name\":'TAU'})\n",
    "\n",
    "#print show_candidates('TAU', '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The End :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
